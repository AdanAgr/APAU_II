{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "054f0cca3061be223d76116cb8544b598eb5a297"
   },
   "source": [
    "# Clustering xerárquico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd0fc89fe26333add074845d0629b52ae828584c"
   },
   "source": [
    "## Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.9.4)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-win_amd64.whl.metadata (15 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (6.5.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading scikit_learn-1.6.1-cp39-cp39-win_amd64.whl (11.2 MB)\n",
      "   ---------------------------------------- 11.2/11.2 MB 13.4 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 11.6/11.6 MB 16.5 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 46.2/46.2 MB 16.9 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, scipy, joblib, scikit-learn, pandas, seaborn\n",
      "Successfully installed joblib-1.4.2 pandas-2.2.3 pytz-2025.1 scikit-learn-1.6.1 scipy-1.13.1 seaborn-0.13.2 threadpoolctl-3.6.0 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy matplotlib scikit-learn seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhierarchy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentación de clientes cun algoritmo de *clustering* xerárquico\n",
    "\n",
    "Usaremos o algoritmo de *clustering* xerárquico aglomerativo para traballar co mesmo *dataset* de clientes do [notebook](02_Clustering.ipynb) da sesión anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos\n",
    "\n",
    "#### Exploración dos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos o dataset co que traballaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://fegalaz.usc.es/~sdocio/apau2/p1/datasets/customers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "067b51b55e3daed31cfed664a1eacde23b932ec1"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e352ff53fe883942afd06b2e830ff7fa7cfdabd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=[\"CustomerID\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57e39b6ed035b3e1b9e3dda9efd273fe552f48a7"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que non hai valores nulos no *dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab264c94de58ad05158ad3bfd95a9fd35f4106de"
   },
   "source": [
    "### Segmentación usando perfil de gasto e ingresos anuais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos as columnas coas que non imos traballar, como `CustomerID` (variable categórica que actúa como identificador único), `Gender` (variable categórica de tipo binario) e `Age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"CustomerID\", \"Gender\", \"Age\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizamos os datos para axustar a escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "X = scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'average'\n",
    "threshold = 0.7\n",
    "distance = 'euclidean'\n",
    "np.set_printoptions(suppress=True, precision=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producimos a matriz de ligazóns (*linkage matrix*), definindo un método (`single`, `complete`, `average`, etc) e unha métrica (`euclidean`, `cosine`, etc). O resultado é unha matriz con forma `(n-1, 4)`, onde cada fila representa cada unha das fusións levadas a cabo nas sucesivas iteracións do proceso de agrupamento xerárquico. As catro columnas son:\n",
    "- Columnas 0 e 1: índices dos *clusters* que se fusionan en cada iteración. Se os valores están entre `0` e `n-1`, refírese a un punto orixinal do dataset. Se é maior ou igual a `n`, refírese a un *cluster* novo, creado nun agrupamento anterior que pode combinar puntos individuais e/ou *clusters*.\n",
    "- Columna 2: distancia entre os *clusters* fusionados.\n",
    "- Columna 3: número total de puntos no novo *cluster* formado pola fusión. O valor vai aumentando a medida que se van fusionando os *clusters*. Na última fila o valor será `n`, xa que é un único *cluster* contendo todos os puntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sch.linkage(X, method=method, metric=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trh = threshold * max(Z[:,2])\n",
    "\n",
    "plt.figure(1, figsize=(15, 8))\n",
    "plt.xlabel('Clientes')\n",
    "plt.ylabel('Distancia')\n",
    "plt.axhline(y=trh, color='r', linestyle='--', label=f'Limiar de corte ({trh:.2f})')\n",
    "dendrogram = sch.dendrogram(Z, color_threshold=trh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4f5806a8c9a5581292b4f16df6977d053f833b7"
   },
   "outputs": [],
   "source": [
    "agg = AgglomerativeClustering(n_clusters=None, distance_threshold=trh, metric='euclidean', linkage=method)\n",
    "cluster_id = agg.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.scatter(x='Annual Income (k$)', y='Spending Score (1-100)', data=df, c=agg.labels_, s=100, cmap='viridis', edgecolors='k')\n",
    "plt.xlabel('Ingresos anuais (k$)')\n",
    "plt.ylabel('Perfil de gasto (1-100)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 42674,
     "sourceId": 74935,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 21695,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
